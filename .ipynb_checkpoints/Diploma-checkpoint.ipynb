{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Импортируем все необходимые библиотеки</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import telethon.sync\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import aiohttp\n",
    "import aiomoex\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import mpld3\n",
    "import sys\n",
    "import time\n",
    "import pymorphy2\n",
    "from string import punctuation\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import scipy.stats\n",
    "# import spacy\n",
    "# from spacy.lang.ru.examples import sentences\n",
    "from deep_translator import (GoogleTranslator,\n",
    "                             PonsTranslator,\n",
    "                             LingueeTranslator,\n",
    "                             MyMemoryTranslator,\n",
    "                             YandexTranslator,\n",
    "                             DeepL,\n",
    "                             QCRI,\n",
    "                             single_detection,\n",
    "                             batch_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Сбор сообщений из телеграмм-каналов</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_id = 1923089\n",
    "api_hash = '8e526e12df9137207e2f7b966924a246'\n",
    "\n",
    "client = telethon.sync.TelegramClient('Kostya3', api_id, api_hash)\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "#Создаем пустые листы и задаём количество наблюдений в выборке равное n*количество телеграмм каналов \n",
    "texts =[]\n",
    "dates = []\n",
    "n=int(input())\n",
    "\n",
    "#Собираем посты из канала РынкиДеньгиВласть\n",
    "async def rdv():\n",
    "    messages = await client.get_messages('https://t.me/AK47pfl', n)\n",
    "    i=0\n",
    "    while i<len(messages):\n",
    "        text = messages[i].text\n",
    "        date = messages[i].date\n",
    "        date = date.replace(tzinfo=None)\n",
    "        texts.append(text)\n",
    "        dates.append(date)\n",
    "        i+=1\n",
    "    return(texts, dates)\n",
    "async with client:\n",
    "    client.loop.run_until_complete(rdv())\n",
    "\n",
    "#Собираем посты из канала Сигналы РЦБ\n",
    "async def signals():\n",
    "    messages = await client.get_messages('https://t.me/cbrstocks', n)\n",
    "    i=0\n",
    "    while i<len(messages):\n",
    "        text = messages[i].text\n",
    "        date = messages[i].date\n",
    "        date = date.replace(tzinfo=None)\n",
    "        texts.append(text)\n",
    "        dates.append(date)\n",
    "        i+=1\n",
    "    return(texts, dates)\n",
    "async with client:\n",
    "    client.loop.run_until_complete(signals())\n",
    "\n",
    "#Формируем базу данных\n",
    "tab = pd.DataFrame({'Дата и время': dates, 'Сообщение': texts})\n",
    "tab = tab.set_index('Дата и время')\n",
    "tab = tab.sort_index()\n",
    "tab.to_csv(\"raw_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Сбор тикеров акций, торгуемых в режиме TQBR</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Для выборки были взяты не все акции, торгующиеся на Мосбирже, а лишь 268 акций, торгуемых в режиме T+0</em>\n",
    "<p><em>Это наиболее популярные акции, которые часто упоминаются в соцсетях</em></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#достаем тикеры акций и их названия с сайта мосбиржи и сохраняем в таблицу\n",
    "async def shares_func():\n",
    "    request_url = \"https://iss.moex.com/iss/engines/stock/markets/shares/boards/TQBR/securities.json\"\n",
    "    arguments = {\"securities.columns\": (\"SECID,\" \"SHORTNAME,\" \"SECNAME\")}\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        iss = aiomoex.ISSClient(session, request_url, arguments)\n",
    "        data = await iss.get()\n",
    "        shares = pd.DataFrame(data[\"securities\"])\n",
    "        shares.to_csv('shares')\n",
    "\n",
    "asyncio.run(shares_func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares = pd.read_csv('shares')\n",
    "shares = shares.drop('Unnamed: 0', axis = 'columns')\n",
    "shares['NewName'] = shares.SHORTNAME.map(lambda x: x[0: x.find(' ')] if ' ' in x else x)\n",
    "shares['NewName'] = shares.NewName.map(lambda x: x[0: x.find('-')] if '-' in x else x)\n",
    "shares['NewName'] = shares.NewName.map(lambda x: x[0: x.find('.')] if '.' in x else x)\n",
    "shares['NewName'] = shares['NewName'].replace('Система', 'АФК Система')\n",
    "shares['NewName'] = shares['NewName'].replace('FIVE', 'X5 RetailGroup')\n",
    "shares['NewName'] = shares['NewName'].replace('FIXP', 'FixPrice')\n",
    "shares['NewName'] = shares['NewName'].replace('Yandex', 'Яндекс')\n",
    "shares['NewName'] = shares['NewName'].replace('+МосЭнерго', 'МосЭнерго')\n",
    "secid = list(shares['SECID'])\n",
    "shortname = list(shares['NewName'])   \n",
    "secid_and_shortname = dict(zip(secid, shortname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Предобработка текста</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>В данной части работы ведётся предварительная обработка текта, для того, чтобы избавить результаты анализа текста от искажений</p>\n",
    "<p>Основные шаги предобработки:</p>\n",
    "<ol>\n",
    "    <li>Удаление неинформативных символов</li>\n",
    "    <li>Замена тикеров на краткие названия, которые удобно искать в тексте</li>\n",
    "    <li>Удаление ссылок и хэштегов</li>\n",
    "    <li>Создание обучающей и тестовой выборки вручную путём присваивания положительного, отрицательного и нейтрального тона</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируем данные\n",
    "raw_data = pd.read_csv(\"raw_text\")\n",
    "raw_data = raw_data.set_index('Дата и время')\n",
    "raw_data = raw_data.dropna()\n",
    "\n",
    "#удаляем ссылки\n",
    "raw_data['Сообщение'] = raw_data['Сообщение'].str.replace(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|\\\n",
    "                                                        (?:%[0-9a-fA-F][0-9a-fA-F]))+\", '', case=False) \n",
    "# удаляем эмодзи\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace(\"[\"u\"\\U0001F600-\\U0001F64F\"  \n",
    "                    u\"\\U0001F300-\\U0001F5FF\" \n",
    "                    u\"\\U0001F680-\\U0001F6FF\" \n",
    "                    u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                    u\"\\U00002500-\\U00002BEF\" \n",
    "                    u\"\\U00002702-\\U000027B0\"\n",
    "                    u\"\\U00002702-\\U000027B0\"\n",
    "                    u\"\\U000024C2-\\U0001F251\"\n",
    "                    u\"\\U0001f926-\\U0001f937\"\n",
    "                    u\"\\U00010000-\\U0010ffff\"\n",
    "                    u\"\\u2640-\\u2642\"\n",
    "                    u\"\\u2600-\\u2B55\"\n",
    "                    u\"\\u200d\"\n",
    "                    u\"\\u23cf\"\n",
    "                    u\"\\u23e9\"\n",
    "                    u\"\\u231a\"\n",
    "                    u\"\\ufe0f\"\n",
    "                    u\"\\u3030\"\n",
    "                    \"]+\", \"\", regex = True)\n",
    "\n",
    "#Удаляем различный информационный мусор\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('[*()@,__•#]', \" \", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('\\n\\n', \" \", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('[\\n]', \"\", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('  ', \" \", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('AK47pfl', \"\", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('[*[(+\\\\\\]\\t]', \"\", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('[:]', \"\", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('[%]', \"процентов\", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('[$\"]', \"долларов\", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('долларов', \" \", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('AK47PFLCHAT', \"\", regex = True)\n",
    "raw_data['Сообщение']=raw_data['Сообщение'].str.replace('\\u200b', \"\", regex = True)\n",
    "raw_data[\"Сообщение\"] = raw_data[\"Сообщение\"].str.replace('[', \"\", regex = True)\n",
    "raw_data[\"Сообщение\"] = raw_data[\"Сообщение\"].str.replace(']', \"\", regex = True)\n",
    "raw_data[\"Сообщение\"] = raw_data[\"Сообщение\"].str.replace('RDVPREMIUMbot', \"\", regex = True)\n",
    "\n",
    "# заменяем тикеры на краткие названия\n",
    "raw_data[\"Сообщение\"] = raw_data[\"Сообщение\"].replace(secid_and_shortname, regex=True)\n",
    "\n",
    "# экспортируем данные\n",
    "raw_data = raw_data.dropna()\n",
    "raw_data.to_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Выгружаем данные по ценам</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Данные грузятся за 4 года, поэтому не все компании попадут в выборку, однако это исправляется простым изменением периода</p>\n",
    "<p>Было решено создать массив данных по всем возможным компаниям, чтобы не грузить данные по каждой компании отдельно</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for name in shares['SECID']:\n",
    "    d[name] = yf.download(name + '.ME', '2017-04-01', '2021-09-30') #Здесь меняем период\n",
    "    if d.get(name).empty == True:\n",
    "        d.pop(name)\n",
    "    else:\n",
    "        for i in range(0,d.get(name).shape[0]-1):\n",
    "            d.get(name).loc[d.get(name).index[i+1],'Rit'] = np.log(d.get(name).iloc[i+1, 4]/d.get(name).iloc[i, 4])\n",
    "        d.get(name)['Rit_norm'] = d.get(name)['Rit'].rolling(window=60).mean()\n",
    "        d.get(name)['𝜀'] = (d.get(name)['Rit'] - d.get(name)['Rit_norm'])*100\n",
    "        d.get(name)['AR'] = d.get(name)['𝜀'].rolling(window=60, min_periods=1).mean()\n",
    "        d.get(name)['CAR'] = d.get(name)['AR'].rolling(window=15, center=True).sum()\n",
    "        #Считаем t-статистику\n",
    "        d.get(name)['for_s2'] = (d.get(name)['𝜀']-d.get(name)['AR'])**2/59\n",
    "        d.get(name)['s2'] = d.get(name)['for_s2'].rolling(window=60, min_periods=1).sum()\n",
    "        d.get(name)['t'] = d.get(name)['AR']/(((d.get(name)['s2']/60))**(1/2))\n",
    "        #Выгружаем критические статистики\n",
    "        d.get(name)['t_crit_left_001'] = scipy.stats.t.ppf(0.01, 59)\n",
    "        d.get(name)['t_crit_right_001'] = scipy.stats.t.ppf(1-0.01, 59)\n",
    "        d.get(name)['t_crit_left_005'] = scipy.stats.t.ppf(0.05, 59)\n",
    "        d.get(name)['t_crit_right_005'] = scipy.stats.t.ppf(1-0.05, 59)\n",
    "        d.get(name)['t_crit_left_01'] = scipy.stats.t.ppf(0.1, 59)\n",
    "        d.get(name)['t_crit_right_01'] = scipy.stats.t.ppf(1-0.1, 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Подсчитываем количество упоминаний в соцсетях</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Подсчет ведется по всем компаниям</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('cleaned_data.csv')\n",
    "data['Дата и время']=pd.to_datetime(data['Дата и время']).apply(lambda x: x.date())\n",
    "for key in d.keys():\n",
    "    Comp_name = shares[shares['SECID'] == key]['NewName'].values[0]\n",
    "    mention = data[data[\"Сообщение\"].str.contains(Comp_name, na=False)]\n",
    "    data['is' + key] = 0\n",
    "    for i in mention.index:\n",
    "        data.loc[data.index[i],'is'+key] = 1\n",
    "data.to_csv('maped_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt={}\n",
    "for key in d.keys():\n",
    "    cnt[key] = pd.pivot_table(data, values=('is' + key), index=['Дата и время'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Перевод сообщений с русского на английский</h3>\n",
    "<p>Это необходимо для того, чтобы была возможность использовать VADER-анализ тональности текста, который работает только для английского языка</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = pd.read_csv('maped_data.csv')\n",
    "tr_data=tr_data.drop('Unnamed: 0', axis = 'columns')\n",
    "tr_data = tr_data.drop(tr_data[tr_data['Сообщение']==' '].index)\n",
    "tr_data = tr_data.reset_index()\n",
    "tr_data['message'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, tr_data.shape[0]-1):\n",
    "    print(i)\n",
    "    try:\n",
    "        tr_data.iloc[i, tr_data.columns.get_loc('message')]=(\n",
    "            GoogleTranslator(source='auto', target='en').translate(text=tr_data.iloc[i, tr_data.columns.get_loc('Сообщение')]))\n",
    "    except:\n",
    "        tr_data.iloc[i, tr_data.columns.get_loc('message')] = ''\n",
    "    clear_output()\n",
    "# tr_data.to_csv('filename.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Анализ тональности текста</h3>\n",
    "<p>На данном этапе используется простой метод анализа тональности текста, у которого есть существенные недостатки:</p>\n",
    "<ol>\n",
    "    <li>Невозможность анализировать русскоязычные тексты => теряется точность после перевода</li>\n",
    "    <li>VADER был обучен не на столь узкоспециализированных данных</li>\n",
    "    <li>Невозможность анализировать предложение с учётом упоминания конкретной компании</li>\n",
    "</ol>\n",
    "<p>Тем не менее такой метод даёт не самую плохую точность 57% верно размеченных сообщений с учётом модифицированной методологии. Кроме того, его не нужно специально обучать => не требуется большая размеченная выборка.</p>\n",
    "<p>О методологии:</p>\n",
    "<ol>\n",
    "    <li>Было принято решение классифицировать данные, исходя из уравнения Score_neu|pos*compound*10</li>\n",
    "    <li>Таким образом учитывается не только тональность, но и эмоциональная сила, с которой подаётся текст</li>\n",
    "    <li>Отсекающим значением было выбрано +-0.75 для позитивного и негативного счёта соответственно</li>\n",
    "    <li>Всё, что внутри этого отрезка, считается нейтральным</li>\n",
    "    <li>Счёт присуждается любой компании из списка из-за ограничений модели</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_data = pd.read_csv('tr_data.csv')\n",
    "tran_data=tran_data.drop('Unnamed: 0', axis = 'columns')\n",
    "tran_data = tran_data.drop(tran_data[tran_data['message']==' '].index)\n",
    "tran_data = tran_data.dropna()\n",
    "tran_data = tran_data.reset_index()\n",
    "tran_data=tran_data.drop('index', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "neg = []\n",
    "neu = []\n",
    "pos = []\n",
    "comp = []\n",
    "for i in range(0, tran_data.shape[0]):\n",
    "    translated=tran_data['message'][i]\n",
    "    neg.append(sia.polarity_scores(translated).get('neg'))\n",
    "    neu.append(sia.polarity_scores(translated).get('neu'))\n",
    "    pos.append(sia.polarity_scores(translated).get('pos'))\n",
    "    comp.append(sia.polarity_scores(translated).get('compound'))\n",
    "scores = pd.DataFrame({'neg': neg, 'neu': neu, 'pos': pos, 'comp': comp})\n",
    "scores['score'] = 0\n",
    "for i in range(0,scores.shape[0]):\n",
    "    if scores.iloc[i,scores.columns.get_loc('neg')]*scores.iloc[i,scores.columns.get_loc('comp')]*10<-0.75:\n",
    "        scores.loc[scores.index[i],'score']=-1\n",
    "    elif scores.iloc[i,scores.columns.get_loc('pos')]*scores.iloc[i,scores.columns.get_loc('comp')]*10>0.75:\n",
    "        scores.loc[scores.index[i],'score']=1\n",
    "    else:\n",
    "        scores.loc[scores.index[i],'score']=0\n",
    "tran_data['neg_score'] = 0\n",
    "tran_data['neu_score'] = 0\n",
    "tran_data['pos_score'] = 0\n",
    "for i in scores[scores['score']==-1].index:\n",
    "        tran_data.loc[tran_data.index[i],'neg_score'] = 1\n",
    "for i in scores[scores['score']==0].index:\n",
    "        tran_data.loc[tran_data.index[i],'neu_score'] = 1\n",
    "for i in scores[scores['score']==1].index:\n",
    "        tran_data.loc[tran_data.index[i],'pos_score'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_neg_score = pd.pivot_table(tran_data, values=('neg_score'), index=['Дата и время'], aggfunc=np.sum)\n",
    "cnt_neu_score = pd.pivot_table(tran_data, values=('neu_score'), index=['Дата и время'], aggfunc=np.sum)\n",
    "cnt_pos_score = pd.pivot_table(tran_data, values=('pos_score'), index=['Дата и время'], aggfunc=np.sum)\n",
    "\n",
    "cnt_neg_score.index=pd.to_datetime(cnt_neg_score.index)\n",
    "cnt_neu_score.index=pd.to_datetime(cnt_neu_score.index)\n",
    "cnt_pos_score.index=pd.to_datetime(cnt_pos_score.index)\n",
    "\n",
    "cnt_score=pd.DataFrame({'neg': cnt_neg_score['neg_score'], 'neu': cnt_neu_score['neu_score'], \n",
    "                        'pos': cnt_pos_score['pos_score']}, index=cnt_neg_score.index)\n",
    "\n",
    "cnt_score['d_neg'] = cnt_score['neg']/(cnt_score['neg']+cnt_score['neu']+cnt_score['pos'])\n",
    "cnt_score['d_neu'] = cnt_score['neu']/(cnt_score['neg']+cnt_score['neu']+cnt_score['pos'])\n",
    "cnt_score['d_pos'] = cnt_score['pos']/(cnt_score['neg']+cnt_score['neu']+cnt_score['pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Графические анализ по компаниям</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Введите тикер акции')\n",
    "company = str(input())\n",
    "print('Период анализа:')\n",
    "print('С какой даты вы хотели бы посмотреть статистику?')\n",
    "period_start = str(input())\n",
    "print('По какую дату вы хотели бы посмотреть статистику?')\n",
    "period_end = str(input())\n",
    "\n",
    "if datetime.strptime(period_end, '%Y-%m-%d').date()<datetime.strptime(period_start, '%Y-%m-%d').date():\n",
    "    print('Последняя дата периода должна быть больше первой')\n",
    "else:\n",
    "    idx = cnt.get(company)[cnt.get(company)['is'+company]>0].index.to_list()\n",
    "    \n",
    "    #цена закрытия\n",
    "    plt.figure(figsize = (15, 8))\n",
    "    plt.plot(d.get(company)[period_start:period_end]['Adj Close'], color = \"black\", label = company + \" close price\")\n",
    "    plt.ylabel('Цена')\n",
    "    plt.xlabel('Дата')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    #Упоминания компании\n",
    "    plt.figure(figsize = (15, 3))\n",
    "    plt.plot(cnt.get(company)[datetime.strptime(period_start, '%Y-%m-%d').date():\n",
    "                              datetime.strptime(period_end,'%Y-%m-%d').date()]['is'+company], \n",
    "                              color='red', linewidth=2, label = 'Количество упоминаний в телеграмм каналах')\n",
    "    plt.ylabel('Кол-во')\n",
    "    plt.xlabel('Дата')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    #Доля положительных/нейтральных/негативных сообщений\n",
    "    plt.figure(figsize = (15, 3))\n",
    "    plt.plot(cnt_score[cnt_score.index.isin(idx)==True][period_start:period_end]['d_neg'], \n",
    "                              color='blue', linewidth=2, label = 'negative')\n",
    "    plt.plot(cnt_score[cnt_score.index.isin(idx)==True][period_start:period_end]['d_neu'], \n",
    "                              color='black', linewidth=2, label = 'neutral')\n",
    "    plt.plot(cnt_score[cnt_score.index.isin(idx)==True][period_start:period_end]['d_pos'], \n",
    "                              color='red', linewidth=2, label = 'positive')\n",
    "    plt.ylabel('Доля')\n",
    "    plt.xlabel('Дата')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()    \n",
    "    \n",
    "    #Аномальная доходность\n",
    "    plt.figure(figsize = (15, 3))\n",
    "    plt.plot(d.get(company)[period_start:period_end]['𝜀'], color = \"blue\", label = company + \" anomalies\")\n",
    "    plt.ylabel('%')\n",
    "    plt.xlabel('Дата')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    #Средняя аномальная доходность\n",
    "    plt.figure(figsize = (15, 3))\n",
    "    plt.plot(d.get(company)[period_start:period_end]['AR'], color = \"black\", label = company + \" AR\")\n",
    "    plt.ylabel('%')\n",
    "    plt.xlabel('Дата')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    #Кумулятивная аномальная доходность\n",
    "    plt.figure(figsize = (15, 3))\n",
    "    plt.plot(d.get(company)[period_start:period_end]['CAR'], color = \"black\", label = company + \" CAR\")\n",
    "    plt.ylabel('%')\n",
    "    plt.xlabel('Дата')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize = (15, 5))\n",
    "    plt.plot(d.get(company)[period_start:period_end]['t'], color = \"green\", \n",
    "             label = company + \" t-статистика\")\n",
    "    plt.plot(d.get(company)[period_start:period_end]['t_crit_left_001'], color = \"red\", \n",
    "             label = company + \" t-крит 0.01\")\n",
    "    plt.plot(d.get(company)[period_start:period_end]['t_crit_right_001'], color = \"red\", \n",
    "             label = company + \" t-крит 0.99\")\n",
    "    plt.plot(d.get(company)[period_start:period_end]['t_crit_left_005'], color = \"blue\", \n",
    "             label = company + \" t-крит 0.05\")\n",
    "    plt.plot(d.get(company)[period_start:period_end]['t_crit_right_005'], color = \"blue\", \n",
    "             label = company + \" t-крит 0.95\")\n",
    "    plt.plot(d.get(company)[period_start:period_end]['t_crit_left_01'], color = \"black\", \n",
    "             label = company + \" t-крит 0.1\")\n",
    "    plt.plot(d.get(company)[period_start:period_end]['t_crit_right_01'], color = \"black\", \n",
    "             label = company + \" t-крит 0.9\")\n",
    "    plt.ylabel('Значение t-статистики')\n",
    "    plt.xlabel('Дата')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    ment = cnt.get(company)[datetime.strptime(period_start, '%Y-%m-%d').date():\n",
    "                              datetime.strptime(period_end,'%Y-%m-%d').date()]['is' + company]\n",
    "    price = d.get(company)[period_start:period_end]['Adj Close']\n",
    "    t = d.get(company)[period_start:period_end]['t']\n",
    "    df1 = pd.DataFrame({'mentions': ment, 'price': price})\n",
    "    df2 = pd.DataFrame({'mentions': ment, 't-stat': t})\n",
    "    \n",
    "    print('Матрица корреляций цены закрытия и упоминаний:\\n',df1.corr())\n",
    "    print('Матрица корреляций t-статистики и упоминаний:\\n',df2.corr())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
